{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anishsundaram1/dl-survey-live-lab-2025/blob/main/notebooks/01_baseline_random_forest_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01 â€” Baseline Random Forest (Student)\n",
        "\n",
        "**Today we will:**\n",
        "1) Load the Adult dataset (classification: `income`).\n",
        "2) Split train/test **first** (avoid leakage).\n",
        "3) Handle missing values (numeric: mean; categorical: most frequent).\n",
        "4) Encode categorical features:\n",
        "   - Label encode **one** column (`sex`)\n",
        "   - One-hot encode the rest\n",
        "5) (Practice) Scale numeric features (StandardScaler).\n",
        "6) Train a **RandomForestClassifier** and evaluate it.\n",
        "7) **Deep dive** into the RF object: attributes & methods.\n",
        "8) Try a few hyperparameters and record results in your `students/experiment_log.md`.\n",
        "9) Peek at **GridSearchCV** (teacher-led demo).\n",
        "\n",
        "> As you work: add short notes in your experiment log (Goal â†’ Setup â†’ Results â†’ Reflection).\n"
      ],
      "metadata": {
        "id": "7kEq4maoG9eW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "V4h1ZDmyHIrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Setup\n",
        "!pip -q install scikit-learn pandas matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "print(\"Ready.\")\n"
      ],
      "metadata": {
        "id": "QzRQw9sKHCK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "XA0TOkgFHMCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load the Adult dataset from OpenML\n",
        "adult = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
        "df = adult.frame.copy()\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "tMjwBsLKHPvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Is this a classification or regression problem?  \n",
        "**Target column:** ???\n"
      ],
      "metadata": {
        "id": "fCor1H6KHaU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose columns & split FIRST"
      ],
      "metadata": {
        "id": "1nGA1kAmHdAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Choose columns (keep it small for speed)\n",
        "numeric_features = [\"age\", \"hours-per-week\", \"education-num\", \"capital-gain\", \"capital-loss\"]\n",
        "categorical_features = [\"workclass\", \"marital-status\", \"occupation\", \"sex\", \"native-country\"]\n",
        "target_col = \"class\"\n",
        "\n",
        "use_cols = numeric_features + categorical_features + [target_col]\n",
        "df = df[use_cols].copy()\n",
        "\n",
        "# 3) Split FIRST (to avoid leakage)\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "XrQpnKQyHkKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why split first?**  \n",
        "So that ....\n"
      ],
      "metadata": {
        "id": "3jkmTckzH6b3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handle missing values"
      ],
      "metadata": {
        "id": "XPllvxCZIBOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Impute missing values\n",
        "# Numeric â†’ mean (try median later if you like)\n",
        "num_imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[numeric_features]),\n",
        "                           columns=numeric_features, index=X_train.index)\n",
        "X_test_num  = pd.DataFrame(num_imputer.transform(X_test[numeric_features]),\n",
        "                           columns=numeric_features, index=X_test.index)\n",
        "\n",
        "# Categorical â†’ most frequent\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "X_train_cat_raw = pd.DataFrame(cat_imputer.fit_transform(X_train[categorical_features]),\n",
        "                               columns=categorical_features, index=X_train.index)\n",
        "X_test_cat_raw  = pd.DataFrame(cat_imputer.transform(X_test[categorical_features]),\n",
        "                               columns=categorical_features, index=X_test.index)\n"
      ],
      "metadata": {
        "id": "FMli46S0IFuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode categoricals"
      ],
      "metadata": {
        "id": "CFuCQDKOITzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Encode categoricals\n",
        "# Label-encode ONE column ('sex'); one-hot the rest\n",
        "label_encode_col = \"sex\"\n",
        "\n",
        "# Copies\n",
        "X_train_processed = X_train_cat_raw.copy()\n",
        "X_test_processed  = X_test_cat_raw.copy()\n",
        "\n",
        "# LabelEncoder: fit on train, apply to test\n",
        "le = LabelEncoder()\n",
        "X_train_processed[label_encode_col] = le.fit_transform(X_train_processed[label_encode_col])\n",
        "X_test_processed[label_encode_col]  = le.transform(X_test_processed[label_encode_col])\n",
        "\n",
        "# One-hot all other categorical columns\n",
        "onehot_cols = [c for c in X_train_processed.columns if c != label_encode_col]\n",
        "\n",
        "# Version-safe: sparse_output (>=1.2) vs sparse (<1.2)\n",
        "try:\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "except TypeError:\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "X_train_ohe_array = ohe.fit_transform(X_train_processed[onehot_cols])\n",
        "X_test_ohe_array  = ohe.transform(X_test_processed[onehot_cols])\n",
        "\n",
        "ohe_feature_names = ohe.get_feature_names_out(onehot_cols)\n",
        "X_train_ohe = pd.DataFrame(X_train_ohe_array, columns=ohe_feature_names)\n",
        "X_test_ohe  = pd.DataFrame(X_test_ohe_array,  columns=ohe_feature_names)\n",
        "\n",
        "# Combine label-encoded + one-hot (reset indices for alignment)\n",
        "label_encoded_train = X_train_processed[[label_encode_col]].reset_index(drop=True)\n",
        "label_encoded_test  = X_test_processed[[label_encode_col]].reset_index(drop=True)\n",
        "X_train_cat = pd.concat([label_encoded_train, X_train_ohe.reset_index(drop=True)], axis=1)\n",
        "X_test_cat  = pd.concat([label_encoded_test,  X_test_ohe.reset_index(drop=True)],  axis=1)\n",
        "\n",
        "X_train_cat.shape, X_test_cat.shape\n"
      ],
      "metadata": {
        "id": "5qFdLucQIW0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflect:**  \n",
        "- When might **label encoding** be risky?  \n",
        "- Why is **one-hot** often safer for models like Logistic Regression or Neural Nets?\n"
      ],
      "metadata": {
        "id": "7WaPWu0jIiOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale numeric features (practice)"
      ],
      "metadata": {
        "id": "-jXtk2ZPItIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Scale numeric features (practiceâ€”even if RF doesnâ€™t need it)\n",
        "scaler = StandardScaler()\n",
        "X_train_num_scaled = pd.DataFrame(scaler.fit_transform(X_train_num), columns=numeric_features)\n",
        "X_test_num_scaled  = pd.DataFrame(scaler.transform(X_test_num),   columns=numeric_features)\n",
        "\n",
        "# Assemble final matrices (reset indices to align rows)\n",
        "X_train_final = pd.concat([X_train_num_scaled.reset_index(drop=True),\n",
        "                           X_train_cat.reset_index(drop=True)], axis=1)\n",
        "X_test_final  = pd.concat([X_test_num_scaled.reset_index(drop=True),\n",
        "                           X_test_cat.reset_index(drop=True)],  axis=1)\n",
        "\n",
        "X_train_final.shape, X_test_final.shape\n"
      ],
      "metadata": {
        "id": "kU1XGWMlIoe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When would you prefer**:\n",
        "- `MinMaxScaler` ?\n",
        "- `RobustScaler` ?\n"
      ],
      "metadata": {
        "id": "vzO9iUMfJyiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train RF + Evaluate"
      ],
      "metadata": {
        "id": "zXu_WfCTJ5fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Train a baseline Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_final, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test_final)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=rf.classes_)\n",
        "sns.heatmap(pd.DataFrame(cm, index=[f\"true_{c}\" for c in rf.classes_],\n",
        "                            columns=[f\"pred_{c}\" for c in rf.classes_]),\n",
        "            annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NrrkQWV1J9Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep dive: RF Object"
      ],
      "metadata": {
        "id": "Ylz6u_gJKHE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Inspect the RF object: attributes & methods\n",
        "print(\"Number of trees:\", rf.n_estimators)\n",
        "print(\"Classes:\", rf.classes_)\n",
        "print(\"Max depth setting:\", rf.max_depth)\n",
        "\n",
        "# Feature importances (top 10)\n",
        "importances = pd.Series(rf.feature_importances_, index=X_train_final.columns).sort_values(ascending=False)\n",
        "importances.head(10)\n"
      ],
      "metadata": {
        "id": "AbIhhT1_KMiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict vs predict_proba\n",
        "pred_label = rf.predict(X_test_final[:5])\n",
        "pred_prob  = rf.predict_proba(X_test_final[:5])\n",
        "pred_label, pred_prob\n"
      ],
      "metadata": {
        "id": "3IC-IU79KZ3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain in your own words:**  \n",
        "- Whatâ€™s the difference between `predict` and `predict_proba`?  \n",
        "- Which would you show in an app UI, and why?\n"
      ],
      "metadata": {
        "id": "68Ks5JhwKlLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tinkering with Hyperparameters"
      ],
      "metadata": {
        "id": "wpocxi6lKrDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Tinker: try one change, re-run report, log in experiment_log.md\n",
        "rf2 = RandomForestClassifier(\n",
        "    n_estimators=200,   # try 50 / 100 / 200 originally 200\n",
        "    max_depth=None,     # try 10 / 20 / None\n",
        "    min_samples_split=2,  # try 2 / 5 originally 2\n",
        "    random_state=42\n",
        ")\n",
        "rf2.fit(X_train_final, y_train)\n",
        "print(classification_report(y_test, rf2.predict(X_test_final)))\n"
      ],
      "metadata": {
        "id": "E0lX_r_jKzsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GridSearchCV"
      ],
      "metadata": {
        "id": "A3mDYVwRLIft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100],\n",
        "    \"max_depth\": [None, 10, 20],\n",
        "}\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42),\n",
        "                    param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid.fit(X_train_final, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Best CV accuracy:\", round(grid.best_score_, 4))\n",
        "print(\"Test accuracy with best params:\", round(grid.best_estimator_.score(X_test_final, y_test), 4))\n"
      ],
      "metadata": {
        "id": "4JhC3gCwLHVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ  Homework: GridSearchCV vs RandomizedSearchCV\n",
        "\n",
        "Today we used **GridSearchCV** to systematically test a small parameter grid.  \n",
        "But GridSearch gets expensive if the parameter space is large.  \n",
        "An alternative is **RandomizedSearchCV**: it samples combinations at random.\n",
        "\n",
        "**Task:**  \n",
        "1. Run the provided code that compares GridSearchCV and RandomizedSearchCV.  \n",
        "2. Note which one is faster, and whether they found similar/better hyperparameters.  \n",
        "3. Add your reflection in `students/experiment_log.md` under \"Run 2\".\n"
      ],
      "metadata": {
        "id": "d-Tm5BGQMkSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n0JB2FXnMkEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define parameter distributions for RandomizedSearch\n",
        "param_dist = {\n",
        "    \"n_estimators\": randint(50, 300),\n",
        "    \"max_depth\": [None, 10, 20, 30],\n",
        "    \"min_samples_split\": randint(2, 10)\n",
        "}\n",
        "\n",
        "# GridSearch (small grid)\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_depth\": [None, 10, 20],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42),\n",
        "                    param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42),\n",
        "                                   param_dist, n_iter=10, cv=3,\n",
        "                                   scoring=\"accuracy\", n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "print(\"Running GridSearchCV...\")\n",
        "grid.fit(X_train_final, y_train)\n",
        "\n",
        "print(\"Running RandomizedSearchCV...\")\n",
        "random_search.fit(X_train_final, y_train)\n",
        "\n",
        "print(\"Best params (GridSearch):\", grid.best_params_)\n",
        "print(\"Best score (GridSearch):\", round(grid.best_score_, 4))\n",
        "\n",
        "print(\"Best params (RandomizedSearch):\", random_search.best_params_)\n",
        "print(\"Best score (RandomizedSearch):\", round(random_search.best_score_, 4))\n"
      ],
      "metadata": {
        "id": "qeSuqgjPMo2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflection Questions\n",
        "- Which method finished faster? Why?  \n",
        "- Did they find similar or different best parameters?  \n",
        "- When would you choose GridSearchCV vs RandomizedSearchCV in practice?  \n"
      ],
      "metadata": {
        "id": "JXhJMbowMvCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ›ï¸ Turn Your Random Forest Into a Gradio App\n",
        "\n",
        "**Goal:** Wrap our already-trained Random Forest (RF) into a tiny web app so anyone can try inputs and see predictions (and confidence).\n",
        "\n",
        "**What you should already have (from the earlier notebook):**\n",
        "- A trained `rf` model.\n",
        "- Preprocessing objects: `num_imputer`, `cat_imputer`, `le` (LabelEncoder for `\"sex\"`), `ohe`, `scaler`.\n",
        "- Feature lists: `numeric_features`, `label_encode_col = \"sex\"`, `onehot_cols`.\n",
        "- The final training matrix `X_train_final` (so we can keep the exact column order).\n",
        "\n",
        "> If you get â€œname is not definedâ€ errors later, scroll up and re-run the cells that define/train these.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fHuKBny0Sdxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 1 â€” Lock in the feature order\n",
        "We must feed the appâ€™s processed row to the model in the **exact** column order used during training.\n",
        "\n",
        "**Action:** Create `feature_order = list(X_train_final.columns)` in a code cell.\n",
        "\n",
        "**Why:** Prevents misalignment (wrong columns â†’ wrong predictions).\n",
        "\n"
      ],
      "metadata": {
        "id": "RJl9rl_bVELG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_order = list(X_train_final.columns)  # numeric (scaled) + categorical block\n"
      ],
      "metadata": {
        "id": "XoFR7LvSVVFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_order"
      ],
      "metadata": {
        "id": "pLPWnpWHZhNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 2 â€” Install & import Gradio\n",
        "Weâ€™ll use Gradio to make a small UI with sliders/dropdowns.\n",
        "\n",
        "**Action:**  \n",
        "- `!pip -q install gradio`  \n",
        "- `import gradio as gr` (+ `pandas`, `numpy` if needed)\n",
        "\n",
        "**Why:** Gradio handles the interface so we focus on ML logic.\n",
        "\n"
      ],
      "metadata": {
        "id": "8ajdBeHkVVgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio\n",
        "import gradio as gr\n",
        "#import pandas as pd\n",
        "#import numpy as np\n"
      ],
      "metadata": {
        "id": "NxkOnuklVmwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 3 â€” Write a `preprocess_input(user_dict)` helper\n",
        "This function should:\n",
        "1. Build a one-row `DataFrame` from the raw UI inputs.\n",
        "2. **Numeric**: impute with `num_imputer` â†’ scale with `scaler`.\n",
        "3. **Categorical**: impute with `cat_imputer` â†’ label-encode the `\"sex\"` column with `le` â†’ one-hot the rest with `ohe`.\n",
        "4. Concatenate numeric + categorical.\n",
        "5. Add any missing columns (fill with 0) and **reorder** using `feature_order`.\n",
        "6. Return a 1-row `DataFrame` ready for `rf.predict` / `rf.predict_proba`.\n",
        "\n",
        "**Why:** The app must apply **the same preprocessing** as training, learned on the train split only.\n",
        "\n"
      ],
      "metadata": {
        "id": "yh97mEN4VoSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(user_dict):\n",
        "    \"\"\"\n",
        "    Apply the SAME transforms as train-time to a single-row user_dict and\n",
        "    return a 1-row DataFrame with columns exactly matching feature_order.\n",
        "    \"\"\"\n",
        "    # 1) Raw one-row frame\n",
        "    df_in = pd.DataFrame(0.0, index=[0], columns=numeric_features + categorical_features)\n",
        "    for col, value in user_dict.items():\n",
        "      df_in[col] = value\n",
        "    # 2) Numeric -> impute -> scale\n",
        "    Xn = pd.DataFrame(num_imputer.transform(df_in[numeric_features]),\n",
        "                      columns=numeric_features)\n",
        "    Xn_scaled = pd.DataFrame(scaler.transform(Xn), columns=numeric_features)\n",
        "\n",
        "    # 3) Categorical -> impute -> label-encode ONE col -> one-hot the rest\n",
        "    df_cat = df_in[categorical_features].copy()\n",
        "    df_cat = pd.DataFrame(cat_imputer.transform(df_cat),\n",
        "                          columns=categorical_features)\n",
        "\n",
        "    # Label-encode the chosen column (assumes no unseen categories)\n",
        "    df_cat.loc[:, label_encode_col] = le.transform(df_cat[label_encode_col])\n",
        "\n",
        "\n",
        "    # one-hot the remaining categoricals (trained with handle_unknown=\"ignore\")\n",
        "    onehot_cols_in_df_cat = [col for col in onehot_cols if col in df_cat.columns]\n",
        "    Xc_ohe = pd.DataFrame(\n",
        "        ohe.transform(df_cat[onehot_cols_in_df_cat]),\n",
        "        columns=ohe.get_feature_names_out(onehot_cols_in_df_cat)\n",
        "    )\n",
        "\n",
        "    # final categorical block = label-encoded col + one-hot block\n",
        "\n",
        "    Xc_final = pd.concat(\n",
        "        [df_cat[[label_encode_col]].reset_index(drop=True),\n",
        "         Xc_ohe.reset_index(drop=True)],\n",
        "        axis=1\n",
        "    )# Finally, by reindexing with feature_order, you guarantee the output has the exact same columns and order as the model expects, filling in any missing one-hot categories with zeros.\n",
        "\n",
        "    # 4) Assemble numeric + categorical\n",
        "    X_final = pd.concat(\n",
        "        [Xn_scaled.reset_index(drop=True), Xc_final.reset_index(drop=True)],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # 5) Enforce EXACT training columns & order in ONE step\n",
        "    # - drops any extra columns\n",
        "    # - inserts any missing one-hot columns filled with 0\n",
        "    #X_final = X_final.reindex(columns=feature_order, fill_value=0)\n",
        "    # at end of preprocess_input\n",
        "    X_final = X_final.reindex(columns=feature_order, fill_value=0) # swapped to feature order\n",
        "    return X_final\n",
        "\n",
        "\n",
        "    #return X_final\n"
      ],
      "metadata": {
        "id": "VispYLHnVuvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 4 â€” Write the `predict(...)` function\n",
        "Keep the UI compact (start with 5 inputs). Good defaults for the rest are fine.\n",
        "\n",
        "**Inputs to expose (suggested):**\n",
        "- `age` (slider)\n",
        "- `hours_per_week` (slider)\n",
        "- `education_num` (slider)\n",
        "- `sex` (radio from training categories)\n",
        "- `workclass` (dropdown from training categories)\n",
        "\n",
        "**Inside `predict`:**\n",
        "- Build a `raw` dict from those inputs (plus reasonable defaults for other features).\n",
        "- Call `preprocess_input(raw)` â†’ `Xf`.\n",
        "- Use `rf.predict(Xf)` for the label.\n",
        "- If available, use `rf.predict_proba(Xf)` and show **P(>50K)**.\n",
        "\n",
        "**Why:** Labels are decisive; probabilities show **confidence** and open the door to threshold choices.\n",
        "\n"
      ],
      "metadata": {
        "id": "NrdRsVt0VvT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "# Simple prediction function returning label + probability of >50K if available\n",
        "def predict(age, hours_per_week, education_num, sex, workclass, marital_status, occupation, n_features, threshold):\n",
        "    raw = {\n",
        "        \"age\": age,\n",
        "        \"hours-per-week\": hours_per_week,\n",
        "        \"education-num\": education_num,\n",
        "        \"sex\": sex,               # label-encoded column\n",
        "        \"workclass\": workclass,   # one-hot\n",
        "        # Defaults for demo (you can expose these later in the UI)\n",
        "        \"marital-status\": marital_status,\n",
        "        \"occupation\": occupation,\n",
        "        \"native-country\": \"United-States\",\n",
        "        \"capital-gain\": 0,\n",
        "        \"capital-loss\": 0,\n",
        "        \"n_features\": n_features,\n",
        "        \"threshold\": threshold\n",
        "    }\n",
        "    Xf = preprocess_input(raw)\n",
        "    label = rf.predict(Xf)[0]\n",
        "    out = f\"Prediction: {label}\"\n",
        "    if hasattr(rf, \"predict_proba\"):\n",
        "        classes = list(rf.classes_)\n",
        "        proba = rf.predict_proba(Xf)[0]\n",
        "        # Show the probability of >50K if that class exists\n",
        "        if \">50K\" in classes:\n",
        "            p = proba[classes.index(\">50K\")]\n",
        "            out += f\"  |  P(>50K) = {p:.2f}\"\n",
        "\n",
        "    if proba[0]>threshold:\n",
        "      value = \"True P is (>50K)\"\n",
        "    else:\n",
        "      value = \"False P is (<=50K)\"\n",
        "\n",
        "    series = pd.Series(rf.feature_importances_, index=X_train_final.columns) # turn feature importance into series\n",
        "    df = series.sort_values(ascending=False).head(n_features).reset_index() # top 10\n",
        "    df.columns = [\"Feature\", \"Importance\"]\n",
        "\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Importance\", title = \"Feature Importances\")\n",
        "    fig.update_layout(\n",
        "        xaxis_tickangle=-45,\n",
        "        xaxis_title=None,\n",
        "        yaxis_title=None\n",
        "    )\n",
        "\n",
        "    return [value,fig]\n"
      ],
      "metadata": {
        "id": "2L5CpVF2V7-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Step 5 â€” Build the UI and launch\n",
        "- Pull choices for `sex` and `workclass` from the **training data** (so no unseen categories).\n",
        "- Create a `gr.Interface(fn=predict, inputs=[...], outputs=\"text\")`.\n",
        "- Call `demo.launch(share=True)` (use `share=False` if tunnels are blocked).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OUQnShGAV9Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_features():\n",
        "    series = pd.Series(rf.feature_importances_, index=X_train_final.columns) # turn feature importance into series\n",
        "    df = series.sort_values(ascending=False).head(10).reset_index() # top 10\n",
        "    df.columns = [\"Feature\", \"Importance\"]\n",
        "    return df"
      ],
      "metadata": {
        "id": "HVTS4oBXUwk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use categories from your training set (already imputed)\n",
        "marital_status = sorted(pd.unique(X_train[\"marital-status\"].dropna()))\n",
        "occupation = sorted(pd.unique(X_train[\"occupation\"].dropna()))\n",
        "workclass_choices = sorted(pd.unique(X_train[\"workclass\"].dropna()))\n",
        "sex_choices = sorted(pd.unique(X_train[\"sex\"].dropna()))\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=[\n",
        "        gr.Slider(17, 90, value=37, step=1, label=\"age\"),\n",
        "        gr.Slider(1, 80, value=40, step=1, label=\"hours_per_week\"),\n",
        "        gr.Slider(1, 16, value=10, step=1, label=\"education_num\"),\n",
        "        gr.Radio(list(sex_choices), label=\"sex\"),\n",
        "        gr.Dropdown(list(workclass_choices), label=\"workclass\"),\n",
        "        gr.Dropdown(list(marital_status), label=\"marital_status\"),\n",
        "        gr.Dropdown(list(occupation), label=\"occupation\"),\n",
        "        gr.Slider(1, 76, value=10, step=1, label=\"n_features\")\n",
        "    ],\n",
        "    outputs=[gr.Textbox(label=\"Model Output\"), gr.Plot(label=\"Feature Importances\")],\n",
        "    title=\"Income Classifier (Random Forest)\",\n",
        "    description=\"Baseline RF wrapped as a Gradio app. Shows label and P(>50K).\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "feat_demo = gr.Interface(\n",
        "    fn=top_features,\n",
        "    inputs=None,\n",
        "    outputs=gr.Dataframe(label=\"Top 10 Features\"),\n",
        "    title=\"Random Forest Feature Importance\",\n",
        "    description=\"Top 10 most important features used by the trained model.\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True, show_error=True)  # use share=False if school network blocks external tunnels\n",
        "feat_demo.launch(share = True, show_error=True)"
      ],
      "metadata": {
        "id": "yN_wvjzIWVzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "marital_status = sorted(pd.unique(X_train[\"marital-status\"].dropna()))\n",
        "occupation = sorted(pd.unique(X_train[\"occupation\"].dropna()))\n",
        "workclass_choices = sorted(pd.unique(X_train[\"workclass\"].dropna()))\n",
        "sex_choices = sorted(pd.unique(X_train[\"sex\"].dropna()))\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Income Classifier (Random Forest)\")\n",
        "    gr.Markdown(\"Baseline RF wrapped as a Gradio app. Shows label and P(>50K).\")\n",
        "\n",
        "    with gr.Tab(\"Prediction\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                age = gr.Slider(17, 90, value=37, step=1, label=\"age\")\n",
        "                hours_per_week = gr.Slider(1, 80, value=40, step=1, label=\"hours_per_week\")\n",
        "                education_num = gr.Slider(1, 16, value=10, step=1, label=\"education_num\")\n",
        "                sex = gr.Radio(sex_choices, label=\"sex\")\n",
        "                workclass = gr.Dropdown(workclass_choices, label=\"workclass\")\n",
        "                marital = gr.Dropdown(marital_status, label=\"marital_status\")\n",
        "                occup = gr.Dropdown(occupation, label=\"occupation\")\n",
        "                n_features = gr.Slider(1, 76, value=10, step=1, label=\"n_features\")\n",
        "                threshold = gr.Slider(0, 1, value=10, step=0.1, label=\"threshold\")\n",
        "                submit_btn = gr.Button(\"Predict\")\n",
        "\n",
        "            with gr.Column():\n",
        "                output_text = gr.Textbox(label=\"Model Output\")\n",
        "                output_plot = gr.Plot(label=\"Feature Importances\")\n",
        "\n",
        "        submit_btn.click(\n",
        "            fn=predict,\n",
        "            inputs=[age, hours_per_week, education_num, sex, workclass, marital, occup, n_features,threshold],\n",
        "            outputs=[output_text, output_plot]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Top Features\"):\n",
        "        gr.Markdown(\"### Random Forest Feature Importance\")\n",
        "        gr.Markdown(\"Top 10 most important features used by the trained model.\")\n",
        "        top_feats = gr.Dataframe(label=\"Top 10 Features\")\n",
        "        load_btn = gr.Button(\"Load Top Features\")\n",
        "        load_btn.click(fn=top_features, inputs=None, outputs=top_feats)\n",
        "\n",
        "demo.launch(share=True, show_error=True)"
      ],
      "metadata": {
        "id": "Yl4Ya51VaAuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(rf.feature_importances_, index=X_train_final.columns).sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "id": "hwxm8KiSUMbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸŒŸ Stretch Challenge (pick one)\n",
        "\n",
        "### A) Add more inputs\n",
        "Expose `marital-status` and/or `occupation` in the UI. Update `predict` to pass them through `preprocess_input`.\n",
        "\n",
        "**Hint:** Keep categorical choices from the training set to avoid unseen-label errors.\n",
        "\n",
        "---\n",
        "\n",
        "### B) Show **feature importance** (top-k)\n",
        "After training, RF has `rf.feature_importances_`. Let users click a button to see the **top 10 features** your model relied on.\n",
        "\n",
        "**How:**\n",
        "- Create a small function that returns a table or text of the top-k from:\n",
        "  - `pd.Series(rf.feature_importances_, index=X_train_final.columns).sort_values(ascending=False).head(10)`\n",
        "\n",
        "**Optional UI idea:**\n",
        "- Add a secondary `gr.Interface` or a `gr.Tab` / `gr.Accordion` that calls this function (e.g., `outputs=\"dataframe\"` or text).\n",
        "- Ask: *Does importance change if you retrain with different hyperparameters?*\n",
        "\n",
        "> Note: RF importances are heuristic; theyâ€™re useful for discussion, not a complete story (advanced: SHAP later).\n",
        "\n",
        "---\n",
        "\n",
        "### C) Precision vs Recall slider (advanced)\n",
        "Let the user pick a **threshold** for classifying `>50K` using `predict_proba`. Show how higher thresholds **increase precision** but **decrease recall**.\n",
        "\n",
        "**How:**\n",
        "- Add a slider 0.0â€“1.0 (â€œDecision Threshold for >50Kâ€).\n",
        "- If `P(>50K) â‰¥ threshold` â†’ predict `>50K`, else `<=50K`.\n",
        "\n",
        "**Discuss:** When would you prefer high precision vs high recall in a real app?\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting Tips\n",
        "- **â€œunseen labelâ€ errors**: Make sure UI choices (e.g., `sex`, `workclass`) come from training categories.  \n",
        "- **Wrong feature order**: Always reorder with `feature_order` before predicting.  \n",
        "- **Variables not defined**: Re-run training/preprocessing cells above or import from your previous notebook.\n",
        "\n",
        "---\n",
        "\n",
        "### Exit Ticket (today)\n",
        "- Launch your app and test 3 scenarios.\n",
        "- Paste one app screenshot + a 2â€“3 sentence reflection in `students/experiment_log.md`."
      ],
      "metadata": {
        "id": "Z8xbiUF1WhMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Mount your drive"
      ],
      "metadata": {
        "id": "4TIiSeD2RmFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change directory to where you want the model to be saved in your drive\n",
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "bJTSQU2zRnyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "print(\"SAVING COMPLETE MODEL PACKAGE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create a complete model package\n",
        "model_package = {\n",
        "    'model': rf,\n",
        "    'preprocessors': {\n",
        "        'num_imputer': num_imputer,\n",
        "        'scaler': scaler,\n",
        "        'cat_imputer': cat_imputer,\n",
        "        'label_encoder': le,\n",
        "        'onehot_encoder': ohe\n",
        "    },\n",
        "    'data': {\n",
        "        'X_train': X_train_final,\n",
        "        'X_test': X_test_final,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "with open('model_package.pkl', 'wb') as f:\n",
        "    pickle.dump(model_package, f)\n",
        "\n",
        "print(\"Saved: model_package.pkl\")"
      ],
      "metadata": {
        "id": "yQ0iaxlOQukj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Downsample the data\n",
        "X_train_downsampled, y_train_downsampled = resample(X_train_final, y_train,\n",
        "                                                    replace=False, n_samples=2000,\n",
        "                                                    random_state=42, stratify=y_train)\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train_downsampled, y_train_downsampled)\n",
        "\n",
        "# Evaluate the SVM classifier\n",
        "y_pred_svm = svm.predict(X_test_final)\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "SRZCjcDfAB1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure you have the necessary preprocessors and feature_order from previous steps\n",
        "# rf, num_imputer, scaler, cat_imputer, le, ohe, feature_order, svm\n",
        "\n",
        "# Prediction function for SVM\n",
        "def predict_svm(age, hours_per_week, education_num, sex, workclass):\n",
        "    raw = {\n",
        "        \"age\": age,\n",
        "        \"hours-per-week\": hours_per_week,\n",
        "        \"education-num\": education_num,\n",
        "        \"sex\": sex,               # label-encoded column\n",
        "        \"workclass\": workclass,   # one-hot\n",
        "        # Defaults for demo (you can expose these later in the UI)\n",
        "        \"marital-status\": \"Never-married\",\n",
        "        \"occupation\": \"Adm-clerical\",\n",
        "        \"native-country\": \"United-States\",\n",
        "        \"capital-gain\": 0,\n",
        "        \"capital-loss\": 0,\n",
        "    }\n",
        "    # Use the existing preprocess_input function\n",
        "    Xf = preprocess_input(raw)\n",
        "    # Use the trained SVM model and return only the label\n",
        "    label = svm.predict(Xf)[0]\n",
        "    return f\"Prediction: {label}\"\n",
        "\n",
        "# Use categories from your training set (already imputed)\n",
        "# Ensure these variables are defined from previous cells\n",
        "workclass_choices = sorted(pd.unique(X_train[\"workclass\"].dropna()))\n",
        "sex_choices = sorted(pd.unique(X_train[\"sex\"].dropna()))\n",
        "\n",
        "svm_demo = gr.Interface(\n",
        "    fn=predict_svm,\n",
        "    inputs=[\n",
        "        gr.Slider(17, 90, value=37, step=1, label=\"age\"),\n",
        "        gr.Slider(1, 80, value=40, step=1, label=\"hours_per_week\"),\n",
        "        gr.Slider(1, 16, value=10, step=1, label=\"education_num\"),\n",
        "        gr.Radio(list(sex_choices), label=\"sex\"),\n",
        "        gr.Dropdown(list(workclass_choices), label=\"workclass\"),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Model Output\"),\n",
        "    title=\"Income Classifier (SVM)\", # Title for SVM app\n",
        "    description=\"SVM model wrapped as a Gradio app. Shows predicted income label.\" # Updated description\n",
        ")\n",
        "\n",
        "svm_demo.launch(share=True, show_error=True) # Launch the SVM Gradio app"
      ],
      "metadata": {
        "id": "m3RM0waEAFiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}